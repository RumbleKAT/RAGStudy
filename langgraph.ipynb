{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T15:32:18.805284Z",
     "start_time": "2024-11-23T15:31:00.061947Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_ollama.llms import OllamaLLM\n",
    "model = OllamaLLM(model=\"llama3:8b\")\n",
    "\n",
    "print(model.invoke(\"who are you?\"))"
   ],
   "id": "7dcd48e20f03fecd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am LLaMA, an AI assistant developed by Meta AI that can understand and respond to human input in a conversational manner. I'm not a human, but a computer program designed to simulate conversation and answer questions to the best of my ability based on my training data.\n",
      "\n",
      "My primary function is to provide information, answer questions, and engage in natural-sounding conversations with humans. I can discuss topics like science, history, entertainment, and more. I can also generate text, translate languages, and even create simple stories or dialogues.\n",
      "\n",
      "I'm constantly learning and improving my responses based on the interactions I have with users like you. This means that over time, I'll become better at understanding what you want to talk about and providing helpful and accurate information.\n",
      "\n",
      "So, who am I? I'm a machine learning model designed to help people communicate and find answers in a fun and engaging way!\n"
     ]
    }
   ],
   "execution_count": 75
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T15:32:19.733168Z",
     "start_time": "2024-11-23T15:32:18.917750Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "loader = WebBaseLoader(\"https://lilianweng.github.io/posts/2023-06-23-agent/\")\n",
    "data = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
    "all_splits = text_splitter.split_documents(data)"
   ],
   "id": "4b8306881ce04275",
   "outputs": [],
   "execution_count": 76
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T15:32:47.203891Z",
     "start_time": "2024-11-23T15:32:19.765549Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "local_embeddings = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "\n",
    "vectorstore = Chroma.from_documents(documents=all_splits, embedding=local_embeddings)"
   ],
   "id": "74d11b4211baf6d9",
   "outputs": [],
   "execution_count": 77
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T15:32:47.267536Z",
     "start_time": "2024-11-23T15:32:47.217895Z"
    }
   },
   "cell_type": "code",
   "source": [
    "question = \"What are the approaches to Task Decomposition?\"\n",
    "docs = vectorstore.similarity_search(question)\n",
    "len(docs)"
   ],
   "id": "d82321afd3050999",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 78
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T15:37:05.772690Z",
     "start_time": "2024-11-23T15:35:31.593575Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"Summarize the main themes in these retrieved docs: {docs}\"\n",
    ")\n",
    "\n",
    "\n",
    "# Convert loaded documents into strings by concatenating their content\n",
    "# and ignoring metadata\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "chain = {\"docs\": format_docs} | prompt | model | StrOutputParser()\n",
    "\n",
    "question = \"What are the approaches to Task Decomposition?\"\n",
    "\n",
    "docs = vectorstore.similarity_search(question)\n",
    "\n",
    "chain.invoke(docs)"
   ],
   "id": "d01eae81b6c3200d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'It seems like there\\'s a bit of repetition in these documents! However, I\\'ll summarize the main themes for you:\\n\\nThe main theme is that Task Decomposition can be achieved through three methods:\\n\\n1. **Large Language Models (LLMs)**: Using simple prompts like \"Steps for XYZ\" or \"What are the subgoals for achieving XYZ?\" to break down a task into smaller steps.\\n2. **Task-specific instructions**: Providing specific guidance, such as \"Write a story outline,\" to help decompose a task.\\n3. **Human inputs**: Involving humans in the process to provide input and guide the decomposition of a task.\\n\\nThese methods can be used separately or in combination to effectively break down complex tasks into manageable parts.'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 80
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T15:42:07.948014Z",
     "start_time": "2024-11-23T15:41:01.904767Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "RAG_TEMPLATE = \"\"\"\n",
    "You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
    "\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "Answer the following question:\n",
    "\n",
    "{question}\"\"\"\n",
    "\n",
    "rag_prompt = ChatPromptTemplate.from_template(RAG_TEMPLATE)\n",
    "\n",
    "chain = (\n",
    "    RunnablePassthrough.assign(context=lambda input: format_docs(input[\"context\"]))\n",
    "    | rag_prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "question = \"What are the approaches to Task Decomposition?\"\n",
    "\n",
    "docs = vectorstore.similarity_search(question)\n",
    "\n",
    "# Run\n",
    "chain.invoke({\"context\": docs, \"question\": question})"
   ],
   "id": "916ee564ba5e1302",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'According to the retrieved context, there are three approaches to Task Decomposition: (1) using LLM with simple prompting, (2) using task-specific instructions, and (3) with human inputs.'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 83
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T15:42:08.001919Z",
     "start_time": "2024-11-23T15:42:07.996125Z"
    }
   },
   "cell_type": "code",
   "source": [
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "qa_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | rag_prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")"
   ],
   "id": "1a5d7c3748bc742a",
   "outputs": [],
   "execution_count": 84
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T15:42:46.106506Z",
     "start_time": "2024-11-23T15:42:28.319006Z"
    }
   },
   "cell_type": "code",
   "source": [
    "question = \"What are the approaches to Task Decomposition?\"\n",
    "\n",
    "qa_chain.invoke(question)"
   ],
   "id": "62b407432d52fe8a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'According to the provided context, there are three approaches to Task Decomposition: (1) by using Large Language Models (LLM) with simple prompting, (2) by using task-specific instructions, and (3) with human inputs.'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 86
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "ab0535507943e65b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
